{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1. Install Selenium**\n",
    "\n",
    "Open bash and run:\n",
    "```bash\n",
    "pip install selenium\n",
    "```\n",
    "**2. Install driver**\n",
    "\n",
    "1. [Download browser driver](https://selenium-python.readthedocs.io/installation.html#drivers)\n",
    "2. Move to a location of choice and unzip."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "import os\n",
    "import time\n",
    "import pandas as pd\n",
    "\n",
    "# Use the link path to your driver:\n",
    "chrome_path = '/Users/data/chromedriver'  # copy and paste the path to your driver here\n",
    "driver = webdriver.Chrome(chrome_path)\n",
    "driver1 = webdriver.Chrome(chrome_path)\n",
    "\n",
    "# Create lists for the dataframe:\n",
    "item_names = list()\n",
    "item_description = list()\n",
    "item_brand = list()\n",
    "review_titles= list()\n",
    "review_contents = list()\n",
    "product_helpful= list() \n",
    "product_not_helpful = list()\n",
    "member_rating = list()\n",
    "total_rate = list()\n",
    "item_prices = list()\n",
    "item_images = list()\n",
    "\n",
    "URL = \"https://ca.iherb.com/c/Vitamins?sr=2&noi=48&p=\"\n",
    "\n",
    "# For a stable scraper, we should scrape all products within 3 pages of the Best Selling vitamin products:\n",
    "\n",
    "for n in range(1,2):\n",
    "    driver.get(f\"{URL}{n}\") # modify the page numbers to scrape the products information\n",
    "    wait = WebDriverWait(driver, 10)\n",
    "\n",
    "    # Store all the links in a list\n",
    "    item_links = [item.get_attribute(\"href\") for item in wait.until(EC.presence_of_all_elements_located((By.CSS_SELECTOR,\".absolute-link-wrapper > a.product-link\")))]\n",
    "\n",
    "    # Iterate over the links\n",
    "    for item_link in item_links:\n",
    "        driver.get(item_link)\n",
    "    \n",
    "        # Locate and click on the `View All Reviews` link\n",
    "        all_reviews_link = wait.until(EC.presence_of_element_located((By.CSS_SELECTOR,\"span.all-reviews-link > a\")))\n",
    "        time.sleep(2)\n",
    "\n",
    "        x = all_reviews_link.get_attribute(\"href\")\n",
    "\n",
    "        MAX_PAGE_NUM = 60   # Scrape maximum 60 pages in the review section\n",
    "\n",
    "        for i in range(1, MAX_PAGE_NUM + 1):\n",
    "            page_num = str(i)\n",
    "            url = x +'?&p='+ page_num \n",
    "            print(url)    \n",
    "            driver1.get(url)\n",
    "            review_containers = driver1.find_elements_by_class_name('review-row')\n",
    "\n",
    "            for containers in review_containers:\n",
    "                driver.implicitly_wait(5) # waiting for the browser to see the website elements\n",
    "                # there are bullet points of the description so we have to join the each bullet point with a comma\n",
    "                elements = ', '.join([item.text for item in driver.find_elements_by_css_selector(\"[itemprop='description'] > ul:nth-of-type(1) > li\")])\n",
    "                # append the item description\n",
    "                item_description.append(elements)\n",
    "                # append the image link of the item\n",
    "                item_images.append(driver.find_element_by_xpath('//*[@id=\"product-image\"]/div[1]/a').get_attribute('href'))\n",
    "                # append the brand of the item\n",
    "                item_brand.append(driver.find_element_by_xpath('.//*[@id=\"brand\"]/a/span/bdi').get_attribute('textContent'))\n",
    "                # append the price of the item\n",
    "                item_prices.append(driver.find_element_by_css_selector('[id=\"price\"]').text)\n",
    "                # append the name of item\n",
    "                item_names.append(driver1.find_element_by_css_selector('[class=\"nav-product-link-text\"] span').text)\n",
    "                # append the total rating score \n",
    "                total_rate.append(driver1.find_element_by_class_name('css-i36p8g').text)\n",
    "                # append the review content       \n",
    "                review_contents.append(containers.find_element_by_class_name('review-text').text)\n",
    "                # append the number of \"helpful\" rating\n",
    "                product_helpful.append(containers.find_element_by_css_selector('[title=\"Helpful\"] span').text)\n",
    "                # append the number of \"not helpful\" rating\n",
    "                product_not_helpful.append(containers.find_element_by_css_selector('[title=\"Unhelpful\"] span').text)\n",
    "                # append the rating star\n",
    "                stars = containers.find_elements_by_class_name(\"css-172co2l\")\n",
    "                rating = 0\n",
    "                for star in stars:\n",
    "                    star_color = star.find_element_by_tag_name(\"path\").get_attribute(\"fill\")\n",
    "                    if star_color != \"transparent\":\n",
    "                        rating += 1\n",
    "                member_rating.append(rating)\n",
    "\n",
    "            time.sleep(2) # Slow the script down\n",
    "\n",
    "driver.quit()\n",
    "\n",
    "data = {'item_image_link' : item_images,\n",
    "        'item_brand' : item_brand, \n",
    "        'item_name' : item_names, \n",
    "        'item_description': item_description, \n",
    "        'item_price' : item_prices, \n",
    "        'total_rating' : total_rating, \n",
    "        'review_contents' : review_contents , \n",
    "        'individual_rating' : member_rating , \n",
    "        'product_helpful' : product_helpful, \n",
    "        'product_not_helpful' : product_not_helpful}\n",
    "\n",
    "# Creates a dataframe \n",
    "\n",
    "df_product = pd.DataFrame(data) \n",
    "\n",
    "# Creates a csv file to the destination path on your computer\n",
    "\n",
    "df_product.to_csv (r'data/iherb_best_selling_products_raw_dataset.csv', index = False, header=True) \n",
    "\n",
    "# Checks the dataframe\n",
    "\n",
    "df_product.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In order to keep the scraper functioning properly, I had to scrape 2 times. \n",
    "# The 1st time, I scraped from page 1 to page 3 ; the 2nd time, I scraped from page 2 to page 3. Then I could concatenate 2 datasets together.\n",
    "\n",
    "data1 = pd.read_csv('data/iherb_best_selling_product_part1.csv')\n",
    "data2 = pd.read_csv('data/iherb_best_selling_product_part2.csv')\n",
    "\n",
    "\n",
    "# Concatenates all data together:\n",
    "\n",
    "frames = [data1, data2]\n",
    "\n",
    "df = pd.concat(frames)\n",
    "\n",
    "# Exports to csv file:\n",
    "\n",
    "df.to_csv (r'data/iherb_best_selling_products_raw_dataset.csv', index = False, header=True) \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}